{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3734324",
   "metadata": {},
   "source": [
    "# RAG skeleton \n",
    "In the following we'll have the skeleton of the RAG system. It is going to be a very basic implementation, that we are going to expand on later milestones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce9dcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.embeddings import resolve_embed_model\n",
    "from llama_index.readers.json import JSONReader\n",
    "from llama_index.core.node_parser import JSONNodeParser\n",
    "from llama_index.readers.file import FlatReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89322f92",
   "metadata": {},
   "source": [
    "### VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b120d2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "with open('./db.txt', \"r\") as file:\n",
    "    connection_string = file.read()\n",
    "\n",
    "conn = psycopg2.connect(connection_string)\n",
    "\n",
    "conn.autocommit = True\n",
    "\n",
    "with conn.cursor() as c:\n",
    "    c.execute(f\"DROP DATABASE IF EXISTS {db_name}\")\n",
    "    c.execute(f\"CREATE DATABASE {db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ffb703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import make_url\n",
    "from llama_index.core import SimpleDirectoryReader, StorageContext\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "import textwrap\n",
    "\n",
    "\n",
    "url = make_url(connection_string)\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    database=db_name,\n",
    "    host=url.host,\n",
    "    password=url.password,\n",
    "    port=url.port,\n",
    "    user=url.username,\n",
    "    table_name=\"rag\",\n",
    "    embed_dim=1024,  # openai embedding dimension\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22905fbe-2806-4a0c-b2e7-ab3fcbf94935",
   "metadata": {},
   "source": [
    "#### Loading and Indexing\n",
    "Load the data in order to make the documents' embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c0ce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = resolve_embed_model(\"local:BAAI/bge-m3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04175eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a path to folder containing all the json files\n",
    "DATA_PATH = \"./data/\"\n",
    "\n",
    "# setting up reader, parser, and llm\n",
    "reader = JSONReader()\n",
    "\n",
    "# parser = JSONNodeParser()     # if we want to split the documents into nodes\n",
    "llm = Ollama(model=\"mistral\", request_timeout=180.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870b8eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# creating the documents out of the json files\n",
    "documents = []\n",
    "for filename in os.listdir(DATA_PATH):\n",
    "    if filename.endswith(\".json\"):\n",
    "        file_path = os.path.join(DATA_PATH, filename)\n",
    "        documents.extend(FlatReader().load_data(Path(file_path)))     # if we want to load the data to then split it into nodes\n",
    "        # documents.extend(reader.load_data(input_file=file_path))\n",
    "parser = JSONNodeParser(include_metadata=True,\n",
    "                        include_prev_next_rel=True)\n",
    "\n",
    "# nodes = parser.get_nodes_from_documents(documents)            # if we want to split documents into nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654594d3-4171-4572-975a-bc3b3b66bb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbdc259-81d4-4f6c-9e81-6e55c1dc98a4",
   "metadata": {},
   "source": [
    "### Document splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c75bafa",
   "metadata": {},
   "source": [
    "if you want to use a simple node parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c0ec0c",
   "metadata": {},
   "source": [
    "if you want to have control on the entire pipeline (can also choose the chunk size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4b9948-3faa-48ab-9a9d-a2aea448c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107733ed-36f0-46fa-80b9-449e3d1bfa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.extractors import (\n",
    "    SummaryExtractor,\n",
    "    QuestionsAnsweredExtractor,\n",
    "    TitleExtractor,\n",
    "    KeywordExtractor,\n",
    ")\n",
    "from llama_index.extractors.entity import EntityExtractor\n",
    "\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "\n",
    "\n",
    "text_splitter = TokenTextSplitter(\n",
    "    # separator=\" \", \n",
    "    chunk_size=512, \n",
    "    chunk_overlap=128\n",
    ")\n",
    "\n",
    "#if you wanna create some custom extractor\n",
    "\n",
    "# class CustomExtractor(BaseExtractor):\n",
    "#     def extract(self, nodes):\n",
    "#         metadata_list = [\n",
    "#             {\n",
    "#                 \"custom\": (\n",
    "#                     node.metadata[\"document_title\"]\n",
    "#                     + \"\\n\"\n",
    "#                     + node.metadata[\"excerpt_keywords\"]\n",
    "#                 )\n",
    "#             }\n",
    "#             for node in nodes\n",
    "#         ]\n",
    "#         return metadata_list\n",
    "\n",
    "transformations = [\n",
    "    text_splitter,\n",
    "    # TitleExtractor(nodes=3,llm=llm),\n",
    "    # QuestionsAnsweredExtractor(questions=2,llm=llm),\n",
    "    # SummaryExtractor(summaries=[\"prev\", \"self\"],llm=llm),\n",
    "    # KeywordExtractor(keywords=4,llm=llm),\n",
    "    EntityExtractor(prediction_threshold=0.5,llm=llm),\n",
    "]\n",
    "\n",
    "\n",
    "pipeline = IngestionPipeline(\n",
    "    transformations=transformations\n",
    ")\n",
    "\n",
    "nodes = pipeline.run(\n",
    "    documents=documents,\n",
    "    in_place=True,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3584d4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff832d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in nodes:\n",
    "    node_embedding = embed_model.get_text_embedding(\n",
    "        node.get_content(metadata_mode=\"all\")\n",
    "    )\n",
    "    node.embedding = node_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff5e82e",
   "metadata": {},
   "source": [
    "### Storing\n",
    "Load into the vectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b6ec85",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1cff36",
   "metadata": {},
   "source": [
    "### Querying (milestone 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af30589",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"General Summarized Overview Large Capacity Cutting Machine 2?\"\n",
    "\n",
    "query_embedding = embed_model.get_query_embedding(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc1996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct vector store query\n",
    "from llama_index.core.vector_stores import VectorStoreQuery\n",
    "\n",
    "query_mode = \"default\"\n",
    "# query_mode = \"sparse\"\n",
    "# query_mode = \"hybrid\"\n",
    "\n",
    "vector_store_query = VectorStoreQuery(\n",
    "    query_embedding=query_embedding, similarity_top_k=2, mode=query_mode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3671b663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a VectorStoreQueryResult\n",
    "query_result = vector_store.query(vector_store_query)\n",
    "print(query_result.nodes[0].get_content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e08e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import NodeWithScore\n",
    "from typing import Optional\n",
    "\n",
    "nodes_with_scores = []\n",
    "for index, node in enumerate(query_result.nodes):\n",
    "    score: Optional[float] = None\n",
    "    if query_result.similarities is not None:\n",
    "        score = query_result.similarities[index]\n",
    "    nodes_with_scores.append(NodeWithScore(node=node, score=score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f0409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import QueryBundle\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from typing import Any, List\n",
    "\n",
    "\n",
    "class VectorDBRetriever(BaseRetriever):\n",
    "    \"\"\"Retriever over a postgres vector store.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vector_store: PGVectorStore,\n",
    "        embed_model: Any,\n",
    "        query_mode: str = \"default\",\n",
    "        similarity_top_k: int = 2,\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        self._vector_store = vector_store\n",
    "        self._embed_model = embed_model\n",
    "        self._query_mode = query_mode\n",
    "        self._similarity_top_k = similarity_top_k\n",
    "        super().__init__()\n",
    "\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieve.\"\"\"\n",
    "        query_embedding = embed_model.get_query_embedding(\n",
    "            query_bundle.query_str\n",
    "        )\n",
    "        vector_store_query = VectorStoreQuery(\n",
    "            query_embedding=query_embedding,\n",
    "            similarity_top_k=self._similarity_top_k,\n",
    "            mode=self._query_mode,\n",
    "        )\n",
    "        query_result = vector_store.query(vector_store_query)\n",
    "\n",
    "        nodes_with_scores = []\n",
    "        for index, node in enumerate(query_result.nodes):\n",
    "            score: Optional[float] = None\n",
    "            if query_result.similarities is not None:\n",
    "                score = query_result.similarities[index]\n",
    "            nodes_with_scores.append(NodeWithScore(node=node, score=score))\n",
    "\n",
    "        return nodes_with_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0091938",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = VectorDBRetriever(\n",
    "    vector_store, embed_model, query_mode=\"default\", similarity_top_k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8119848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(retriever, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adae721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584112fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93cbb6d",
   "metadata": {},
   "source": [
    "### Querying strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ccbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we work with nodes\n",
    "#vector_index = VectorStoreIndex.from_documents(nodes, embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3695f0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we work with documents\n",
    "vector_index = VectorStoreIndex.from_documents(documents, embed_model=embed_model, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361e8f26-c9d6-42c4-abdf-ee99902f6c72",
   "metadata": {},
   "source": [
    "we use top-k similarity strategy to get the k most similar documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d953c9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = vector_index.as_query_engine(llm=llm, verbose=True, similarity_top_k=2)\n",
    "retriever = vector_index.as_retriever(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc338af",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "We test the RAG system with some queries regarding the data in the json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824809e8-dccf-48f1-87e6-da046ed04820",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = query_engine.query(\"What was the average  of Assembly Machines?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516703f5-8d1e-4c51-bc1b-051734aaac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = query_engine.query(\"What was the average consumption of machines?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaaa4d3-bd83-47b1-92ad-275a80ab1016",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = query_engine.query(\"List the conspumption for each machine in March 2024?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d774768-f272-435d-bd40-a4ad2aaf282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = query_engine.query(\"General Summarized Overview Large Capacity Cutting Machine 2?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1b6684-5002-4470-bd84-dd143163b713",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = query_engine.query(\"Which machine has higher idle time\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d553ce3-cf5f-48c2-9278-aa6655546964",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.retrieve(\"General Summarized Overview Assembly Machine 1?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812da437-0f18-45cd-89c0-76dcfd86d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = query_engine.query(\"Which one was more effective and productive: Medium Capacity machine 1 vs Medium Capacity machine 2?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca4cb0f",
   "metadata": {},
   "source": [
    "### JSON Outputs\n",
    "The idea is to define 2 prompts, one for each type of query: `report generation` and `KPI suggestion`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c13db7a",
   "metadata": {},
   "source": [
    "#### Prompt Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee4207-6028-4bb6-b4d0-955408ca022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prompt for Generating New KPIs:\n",
    "kpi_json_prompt = \"\"\"\n",
    "You are a specialized assistant that only outputs answers in JSON format. \n",
    "\n",
    "Analyze the documents and provide new KPI suggestions. Use the JSON format below:\n",
    "{\n",
    "  \"KPIs\": [\n",
    "    {\n",
    "      \"name\": \"<KPI Name>\",\n",
    "      \"description\": \"<Brief description of the KPI>\",\n",
    "      \"formula\": \"<Mathematical Formula to calculate the KPI using existing variables>\"\n",
    "    },\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee02619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Prompt for Generating Machine Reports:\n",
    "report_json_prompt = \"\"\"\n",
    "You are a specialized assistant that only outputs answers in JSON format.\n",
    "\n",
    "Based on the monthly aggregated KPI data provided, generate a detailed report for the specified machine and month. Use the JSON format below:\n",
    "{\n",
    "    \"MachineBehaviorReport\": {\n",
    "        \"machine\": \"<Machine Name>\",\n",
    "        \"month\": \"<Month>\",\n",
    "        \"kpi_analysis\": [\n",
    "            {\n",
    "                \"kpi\": \"<KPI Name>\",\n",
    "                \"analysis\": \"<Analysis of the KPI based on min, max, and average values>\"\n",
    "            },\n",
    "            ...\n",
    "        ],\n",
    "        \"overall_summary\": \"<High-level summary of machine performance>\"\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb92fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More detailed version of the prompt for generating machine reports\n",
    "report_json_prompt2 = \"\"\"\n",
    "You are a specialized assistant that only outputs answers in JSON format.\n",
    "\n",
    "Based on the monthly aggregated KPI data provided, generate a detailed report for the specified machine and month. The report must include the following:\n",
    "\n",
    "1. The name of the machine and the month being analyzed.\n",
    "2. An analysis of each KPI (listed below), comparing its minimum, maximum, and average values. Identify:\n",
    "   - Notable patterns or trends (e.g., consistently high or low values).\n",
    "   - Significant deviations (e.g., high max values with low averages).\n",
    "   - Missing or zero values, and their implications.\n",
    "3. An overall summary of the machine's performance for the month, including conclusions about efficiency, potential issues, and general observations.\n",
    "\n",
    "KPIs to analyze:\n",
    "- average_cycle_time\n",
    "- bad_cycles\n",
    "- consumption\n",
    "- consumption_idle\n",
    "- consumption_working\n",
    "- cost\n",
    "- cost_idle\n",
    "- cost_working\n",
    "- cycles\n",
    "- good_cycles\n",
    "- idle_time\n",
    "- offline_time\n",
    "- power\n",
    "- working_time\n",
    "\n",
    "Respond in the following JSON format:\n",
    "\n",
    "{\n",
    "    \"MachineBehaviorReport\": {\n",
    "        \"machine\": \"<Machine Name>\",\n",
    "        \"month\": \"<Month>\",\n",
    "        \"kpi_analysis\": [\n",
    "            {\n",
    "                \"kpi\": \"<KPI Name>\",\n",
    "                \"analysis\": \"<Analysis of the KPI based on min, max, and average values>\"\n",
    "            },\n",
    "            ...\n",
    "        ],\n",
    "        \"overall_summary\": \"<High-level summary of machine performance>\"\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f2f25c",
   "metadata": {},
   "source": [
    "#### Query Classification\n",
    "Given a query we should find a way to choose the proper prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596239f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_query(query):\n",
    "    kpi_keywords = [\"KPI\", \"KPIs\", \"metrics\", \"new\", \"suggest\"]\n",
    "    report_keywords = [\"report\", \"behavior\", \"trend\", \"machine\"]\n",
    "\n",
    "    if any(keyword in query.lower() for keyword in kpi_keywords):\n",
    "        return \"kpi\"\n",
    "    elif any(keyword in query.lower() for keyword in report_keywords):\n",
    "        return \"report\"\n",
    "    else:\n",
    "        return \"unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981943f7",
   "metadata": {},
   "source": [
    "#### Response Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9400c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(query):\n",
    "    # Classify the query type\n",
    "    query_type = classify_query(query)\n",
    "    \n",
    "    # Select the appropriate prompt\n",
    "    if query_type == \"kpi\":\n",
    "        prompt = kpi_json_prompt\n",
    "    elif query_type == \"report\":\n",
    "        prompt = report_json_prompt\n",
    "    else:\n",
    "        prompt = \"\"\" \"\"\"  # no prompt if uncertain / a different type of query was made\n",
    "\n",
    "    # Pass the query and prompt to the model\n",
    "    response = query_engine.query(prompt + \"\\nQuery: \" + query)\n",
    "\n",
    "    # # Validate the response if it's a 'kpi' or 'report' query\n",
    "    # if query_type in [\"kpi\", \"report\"]:\n",
    "    #     try:\n",
    "    #         # Try parsing the response as JSON\n",
    "    #         response_json = json.loads(response)\n",
    "    #         return response_json\n",
    "    #     except json.JSONDecodeError:\n",
    "    #         # Return an error if the response is not valid JSON\n",
    "    #         return {\"error\": \"Invalid JSON response from model.\", \"raw_response\": response}\n",
    "    \n",
    "    # If the query is not of type 'kpi' or 'report', return the raw response\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac19e9f",
   "metadata": {},
   "source": [
    "#### Examples of Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e452ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Generate a performance report for the machine 'Large Capacity Cutting Machine 2' for March 2024.\"\n",
    "response = get_response(query)\n",
    "\n",
    "print(response)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ac46d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Suggest new KPIs based on the provided data.\"\n",
    "response = get_response(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d932433",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Generate a new KPI to monitor the production efficiency.\"\n",
    "response = get_response(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1c2876",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What was the behavior of the Laser Cutter in March 2024?\"\n",
    "response = get_response(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e76e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"General Summarized Overview of the Laser Cutter?\" # this won't be classified as 'report'\n",
    "response = get_response(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560f3507",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Generate a report on the general behavior of the Riveting Machine and Laser Cutter in March 2024.\"\n",
    "response = get_response(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d4eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How many machines are there?\"\n",
    "response = get_response(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497e2594-a8b3-44ec-b800-034165178616",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
